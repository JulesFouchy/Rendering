{"searchDocs":[{"title":"Pipeline de Rendu","type":0,"sectionRef":"#","url":"/Rendering/Deep dive","content":"Pipeline de Rendu Voici une vue d'ensemble de tout ce qui se passe dans Unreal : Pour faire plus simple, voici ce qu'il faut retenir sur les bases du rendu 3D en rasterisation : Que vous pouvez retrouver expliquées dans cette super vidéo :","keywords":"","version":"Next"},{"title":"Anti-Aliasing","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/Anti-Aliasing","content":"","keywords":"","version":"Next"},{"title":"Qu'est-ce que l'aliasing ?​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#quest-ce-que-laliasing-","content":" Quand vous essayez de dessiner une ligne en diagonale, elle ne peut pas aller &quot;tout droit&quot;, elle est obligée de suivre la grille de pixels, c'est &quot;l'effet escalier&quot; :    Ce qui, vu de loin, donne un aspect rugueux :    L'anti-aliasing consiste à &quot;flouter&quot; l'objet pour que, vu de loin, il apparaisse plus lisse :    ","version":"Next","tagName":"h2"},{"title":"Les différentes techniques d'anti-aliasing​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#les-différentes-techniques-danti-aliasing","content":"     ","version":"Next","tagName":"h2"},{"title":"SSAA (Super-Sampling Anti-Aliasing)​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#ssaa-super-sampling-anti-aliasing","content":" ➕ Excellente qualité quand on monte le nombre de samples (e.g. 64) ➖ Très coûteux en performance ➖ Très mauvais ratio qualité / performance  La plus vieille technique d'anti-aliasing, elle est très simple : elle revient à dessiner sur une image N fois plus grande (N = nombre de samples), puis à la downscale à la taille désirée. Ca marche très bien, mais ça prend beaucoup de temps.  ","version":"Next","tagName":"h3"},{"title":"MSAA (Multi-Sampling Anti-Aliasing) et​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#msaa-multi-sampling-anti-aliasing-et","content":" Similaire à SSAA, en un peu moins quali et un peu meilleur en performance, mais reste très coûteux et a un mauvais ratio qualité / performance.  ","version":"Next","tagName":"h3"},{"title":"FXAA (Fast Approximate Anti-Aliasing)​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#fxaa-fast-approximate-anti-aliasing","content":" Une technique de post-processing, qui détecte les contours des objets et les floute. Relativement efficace et quali, mais a été remplacée par SMAA, qui fait la même chose en mieux.  ","version":"Next","tagName":"h3"},{"title":"SMAA (Subpixel Morphological Anti-Aliasing)​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#smaa-subpixel-morphological-anti-aliasing","content":" Technique récente, très quali, comme FXAA en plus quali, mais un peu plus coûteux.  ","version":"Next","tagName":"h3"},{"title":"TXAA (Temporal Anti-Aliasing)​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#txaa-temporal-anti-aliasing","content":" Anti-aliasing pour les objets qui bougent.  ","version":"Next","tagName":"h3"},{"title":"TAA (Temporal Anti-Aliasing)​","type":1,"pageTitle":"Anti-Aliasing","url":"/Rendering/Deep dive/Anti-Aliasing#taa-temporal-anti-aliasing","content":" À ne pas confondre avec TXAA! Les deux techniques n'ont rien à voir. TXAA gère les objets en mouvement, là où TAA réutilise les frames précédentes pour améliorer l'anti-aliasing.  Réutilise les informations des frames précédentes pour faire du &quot;multisampling&quot;. Elle est donc quasiment aussi quali que SSAA, mais sans l'énorme coût en performance. Technique très quali, très bon rapport qualité / performance, et sur laquelle de nombreux autre effets se basent. Elle a une place importante dans le pipe de rendu de tous les moteurs modernes. Rarement exposé dans les settings graphiques, car on ne peut pas le désactiver, puisque plein d'autres effets en dépendent. ","version":"Next","tagName":"h3"},{"title":"LOD - Level of Detail","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/LOD - Level of Detail","content":"LOD - Level of Detail","keywords":"","version":"Next"},{"title":"Graphics Settings","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/Graphics Settings","content":"","keywords":"","version":"Next"},{"title":"Activité​","type":1,"pageTitle":"Graphics Settings","url":"/Rendering/Deep dive/Graphics Settings#activité","content":" Allez dans votre jeu vidéo préféré, ou dans Unreal, ou Blender (utilisez EEVEE comme moteur de rendu, car c'est un moteur en rasterization, donc plus proche des moteurs de rendu de jeu vidéo).  ","version":"Next","tagName":"h2"},{"title":"Explications​","type":1,"pageTitle":"Graphics Settings","url":"/Rendering/Deep dive/Graphics Settings#explications","content":" Je recommande ces deux vidéos :     ","version":"Next","tagName":"h2"},{"title":"Normal maps","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/Normal maps","content":"","keywords":"","version":"Next"},{"title":"Qu'est-ce qu'une normal map ?​","type":1,"pageTitle":"Normal maps","url":"/Rendering/Deep dive/Normal maps#quest-ce-quune-normal-map-","content":" Une normal map permet de rajouter des détails et une impression de relief sur un mesh avec relativement peu de triangles. Cela permet d'économiser beaucoup de performances, et est donc indispensable pour les assets d'un jeu vidéo !  Les normales d'un modèle sont les informations qui indiquent dans quelle direction la surface est orientée, et elles permettent de calculer les effets de lumière. Ce sont les flèches grises sur ce schéma :  Par défaut, elles sont calculées en fonction des triangles, et donc plus il y a de triangles plus les normales sont variées et rajoutent du relief. Mais il est possible de sauvegarder ces normales dans une texture, afin que chaque pixel du triangle ait une normale différente. On peut ainsi garder les informations des normales, même en ayant moins de triangles.  La seule chose qu'on perd avec une normal map, c'est le volume réel : en mettant votre vue rasante avec l'objet, vous verrez qu'il est plat et l'illusion est cassée.  ","version":"Next","tagName":"h2"},{"title":"TP : créer une normal map​","type":1,"pageTitle":"Normal maps","url":"/Rendering/Deep dive/Normal maps#tp--créer-une-normal-map","content":" Pour ce TP nous allons utiliser Blender. Si vous ne l'avez pas déjà, vous pouvez le télécharger ici. NB : j'utilise la version 4.1 de Blender (la dernière en date), mais vous devriez pouvoir suivre avec n'importe quelle version de Blender.Téléchargez le modèle qui nous servira d'exemple et importez-le dans Blender. (Si vous avez Blender 4.1, il vous suffit de drag'n drop le fichier. Et sinon, allez dans le menu File &gt; Import &gt; Wavefront (.obj))En affichant le wireframe du mesh, vous verrez qu'il contient ÉNORMÉMENT de triangles. C'est très bien pour du cinéma où on veut la qualité maximale, mais pour du jeu vidéo le coût en performance sera beaucoup trop élevé, pour un gain de qualité pas si important. On a moyen de beaucoup alléger le mesh, tout en gardant une grosse partie des détails, grâce à une normal map.Vous pouvez afficher le nombre de triangles en activant les statistiquesPour créer une normal map, suivez le tuto ci-dessous. Lors du decimate (réduction du nombre de triangles), vous pouvez mettre le ratio à 0.001 (Vous pouvez aussi expérimenter avec d'autres ratios, et voir jusqu'où vous pouvez aller tout en préservant la qualité du rendu. Vous pouvez même créer un simple cylindre, le rendu sera pas mal du tout !)   ","version":"Next","tagName":"h2"},{"title":"Tesselation","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/Tesselation","content":"Tesselation Rajoute de la géométrie automatiquement sur les meshs proches, pour qu'ils aient d'avantage de détails. Permet essentiellement d'ensuite appliquer une displacement map. https://youtu.be/1UcBwsQTwwI?t=348","keywords":"","version":"Next"},{"title":"VSync","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/VSync","content":"VSync Evite le tearing, en limitant le framerate. Risque : si le jeu tourne à un poil moins de 60fps, genre 59fps, alors il va automatiquement devoir se limiter à 30fps pour rester sync avec l'écran. GSync : tech dans certains écrans, qui les fait se refresh dès qu'ils recoivent une nouvelle image de la carte graphique. Comme ça c'est l'écran qui s'adapte à la CG et plus l'inverse, donc on peut rendre les frames aussi vite qu'on veut / peut. https://youtu.be/1UcBwsQTwwI?t=249","keywords":"","version":"Next"},{"title":"Shadow maps & Ambient Occlusion","type":0,"sectionRef":"#","url":"/Rendering/Deep dive/Shadow maps & Ambient Occlusion","content":"","keywords":"","version":"Next"},{"title":"Shadow Map​","type":1,"pageTitle":"Shadow maps & Ambient Occlusion","url":"/Rendering/Deep dive/Shadow maps & Ambient Occlusion#shadow-map","content":" ","version":"Next","tagName":"h2"},{"title":"Qu'est-ce qu'une shadow map ?​","type":1,"pageTitle":"Shadow maps & Ambient Occlusion","url":"/Rendering/Deep dive/Shadow maps & Ambient Occlusion#quest-ce-quune-shadow-map-","content":" L'idée est de prendre un screenshot depuis le point de vue de la caméra, pour savoir ce qu'elle peut et ne peut pas &quot;voir&quot;, et donc en déduire ce qui est dans la lumière ou dans l'ombre.  AvecSans  Pour tester les shadow maps et l'occlusion ambiante, vous pouvez aller sur ce site, télécharger IMACUBES-Windows.zip, le dézipper, et lancer IMACUBES.exe.    Et vous pouvez activer / désactiver les ombres et changer leurs paramètres :  ","version":"Next","tagName":"h3"},{"title":"Limites​","type":1,"pageTitle":"Shadow maps & Ambient Occlusion","url":"/Rendering/Deep dive/Shadow maps & Ambient Occlusion#limites","content":" Sur cette vidéo on voit une des limitations : seuls les objets proches ont des ombres, et elles apparaissent subitement quand on se rapproche des objets.  ","version":"Next","tagName":"h3"},{"title":"Ambient Occlusion​","type":1,"pageTitle":"Shadow maps & Ambient Occlusion","url":"/Rendering/Deep dive/Shadow maps & Ambient Occlusion#ambient-occlusion","content":" Les shadow maps à elles seules ne suffisent pas à capturer toutes les ombres possibles de manière photoréaliste. C'est pourquoi d'autres techniques viennent les complémenter. L'ambient occlusion s'occupe d'obscurcir les petits recoins.  AvecSans ","version":"Next","tagName":"h2"},{"title":"Intro","type":0,"sectionRef":"#","url":"/Rendering/M1 GP/Intro","content":"Intro Dans ce cours nous allons écrire notre petit moteur de rendu from scratch, en C++ et en utilisant l'API OpenGL. Le but est que vous découvriez les différents concepts qui sont au cœur d'un moteur de rendu 3D, et que vous compreniez mieux ce qu'il se passe derrière vos outils préférés (Unreal, Unity, Blender, etc.). Nous allons parler de : MeshVertex BufferIndex BufferVertex ShaderFragment ShaderVariables uniformesCaméraMatrice de vueMatrice de projectionMatrice modèleDepth BufferTexturesModèles d'éclairage (Blinn–Phong, PBR)Post-processingRender TargetOmbres (Shadow Maps) À chaque séance je ferai un petit point de cours (30 min max) pour vous expliquer un concept en détail, puis vous serez en autonomie pour avancer sur les TPs. N'hésitez surtout pas à me poser plein de questions, et à m'appeler dès que vous êtes bloqué.es plus de 5-10 minutes sur quelque chose. Vous serez évalué.es sur ces TPs qu'il faudra me rendre. Il y aura deux notes, une au milieu du trimestre et une à la fin. Il est donc important d'avancer régulièrement, car vous serez évalué.es au milieu du trimestre sur là où vous en êtes. Il y a quelques sections qui sont marquées Bonus dans les TPs, vous n'êtes pas obligé.es de les faire, mais si vous en avez le temps et l'envie n'hésitez pas, ça sera valorisé dans la notation. NB : Votre implication et votre participation en classe influencerons aussi (légèrement) votre note. IMPORTANT Vous devriez avoir le temps de faire les TPs avec le temps qu'on a en classe, ne vous sentez pas obligé.es d'avancer à la maison. (Et si les TPs s'avèrent être trop longs pour tout le monde, faites-le moi savoir et j'adapterai mes exigences, pas de panique). Le rendu de vos TPs se fera via GitHub / GitLab, en me mettant un lien sur ce Google Sheet. Faites bien des commits à chaque étape des TPs (en gros à chaque screenshot dans le TP) ! J'irai les regarder pour voir les choses qui se font effacer au cours du temps (comme le premier triangle que vous allez dessiner par exemple). N'hésitez pas à me faire des retours sur tout problème qu'il pourrait y avoir ! Ce qui m'importe c'est que ce cours soit intéressant et enrichissant pour vous, donc je peux le faire évoluer et le changer si il ne vous convient pas !","keywords":"","version":"Next"},{"title":"Intro","type":0,"sectionRef":"#","url":"/Rendering/M2 GP/Intro","content":"Intro","keywords":"","version":"Next"},{"title":"Ressources","type":0,"sectionRef":"#","url":"/Rendering/Ressources","content":"Ressources Acerola : super chaîne Youtube qui vulgarise des concepts / techniques de rendu, et décortique le rendu de certains jeux vidéos Vidéo : Les éléments de base du rendu 3D vulgarisés Vidéos : Cours avancé : Explication détaillée du pipeline de rendu et de plusieurs techniques de rendu Vidéos : Cours avancé : Comment écrire son propre moteur de rendu en C++ et OpenGL","keywords":"","version":"Next"},{"title":"Partie 3 - Du vrai rendu 3D","type":0,"sectionRef":"#","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D","content":"","keywords":"","version":"Next"},{"title":"Loader un mesh depuis un fichier​","type":1,"pageTitle":"Partie 3 - Du vrai rendu 3D","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D#loader-un-mesh-depuis-un-fichier","content":" ","version":"Next","tagName":"h2"},{"title":"Premier modèle d'éclairage et Normales​","type":1,"pageTitle":"Partie 3 - Du vrai rendu 3D","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D#premier-modèle-déclairage-et-normales","content":" ","version":"Next","tagName":"h2"},{"title":"Post-processing et Render Target (Framebuffer)​","type":1,"pageTitle":"Partie 3 - Du vrai rendu 3D","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D#post-processing-et-render-target-framebuffer","content":" ","version":"Next","tagName":"h2"},{"title":"Ombres​","type":1,"pageTitle":"Partie 3 - Du vrai rendu 3D","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D#ombres","content":" ","version":"Next","tagName":"h2"},{"title":"Effet see-through​","type":1,"pageTitle":"Partie 3 - Du vrai rendu 3D","url":"/Rendering/M1 GP/Partie 3 - Du vrai rendu 3D#effet-see-through","content":" -&gt; depth buffer ","version":"Next","tagName":"h2"},{"title":"Partie 1 - Setup","type":0,"sectionRef":"#","url":"/Rendering/M1 GP/Partie 1 - Setup","content":"","keywords":"","version":"Next"},{"title":"Installer Git​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-git","content":" Téléchargez 64-bit Git for Windows Setup depuis cette page. Vous pouvez laisser toutes les options par défaut et installer.  Git est un outil de versioning qui vous permettra de sauvegarder votre code régulièrement, et de me le partager.  ","version":"Next","tagName":"h2"},{"title":"Installer un compilateur C++​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-un-compilateur-c","content":" Téléchargez Build Tools for Visual Studio 2022 depuis cette page, lancez l'exe, puis cochez Desktop development with C++ et installez.    Un compilateur va transformer votre code en un programme exécutable. Vous ne l'utiliserez pas directement, mais il est nécessaire pour que tout build correctement.  ","version":"Next","tagName":"h2"},{"title":"Installer CMake​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-cmake","content":" Téléchargez Windows x64 Installer depuis cette page. IMPORTANT : pendant l'installation, cochez bien Add CMake to the system PATH for the current user (ou Add CMake to the system PATH for all users).    CMake est l'outil de build le plus répandu pour C++. Il explique au compilateur comment compiler votre projet. Vous ne l'utiliserez pas directement, mais il est nécessaire pour que tout build correctement.  ","version":"Next","tagName":"h2"},{"title":"Installer VSCode​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-vscode","content":" Téléchargez-le depuis cette page.  VSCode est l'IDE (&quot;éditeur de texte&quot;) que je vous conseille d'utiliser pour écrire votre code C++. (Vous pouvez utiliser un autre IDE si vous voulez, mais ce cours n'expliquera pas comment le setup pour faire compiler votre projet).  ","version":"Next","tagName":"h2"},{"title":"Installer les extensions VSCode pour C++​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-les-extensions-vscode-pour-c","content":" cpptools-extension-pack: Les extensions C++ de base, obligatoires pour compiler votre projet.webgl-glsl-editor: L'extension GLSL, pour avoir de l'autocomplétion quand vous écrirez des shaders.BuildOutputColorizer: Pour que les messages d'erreur apparaissent en rouge dans la console, très pratique.code-spell-checker: Un correcteur d'orthographe. Marche pour l'anglais et le français. (Pour le configurer pour le français, installez en plus code-spell-checker-french et suivez les instructions qui sont sur la page de téléchargement).vscode-great-icons: Des icônes pour plein de types de fichier (.cpp, .hpp, CMakeLists.txt, etc.).cmake-language-support-vscode: Autocomplétion pour CMake.  ","version":"Next","tagName":"h2"},{"title":"Installer RenderDoc​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#installer-renderdoc","content":" Téléchargez-le depuis cette page.  RenderDoc est un débugueur pour GPU. Il permet de voir tout ce qu'il s'est passé dans la carte graphique pendant le rendu d'une frame donnée. Il permet de voir l'état de vos meshs, les différentes étapes de la construction de l'image finale, et plein d'autres choses encore ! Nous allons beaucoup nous en servir au fil des TPs, à la fois pour débuguer notre code, et aussi juste pour inspecter et mieux comprendre ce qu'il se passe dans la carte graphique.  ","version":"Next","tagName":"h2"},{"title":"Télécharger la base de code​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#télécharger-la-base-de-code","content":" Vous êtes maintenant prêt.e à coder ! Nous allons partir de ce template de code qui inclue toutes les libraires nécessaires. Vous pouvez directement créer un repository GitHub à partir de celui-ci en faisant Use this template :    (Et sinon vous pouvez aussi juste télécharger le code normalement, et créer un repo de votre côté).  ","version":"Next","tagName":"h2"},{"title":"Compiler​","type":1,"pageTitle":"Partie 1 - Setup","url":"/Rendering/M1 GP/Partie 1 - Setup#compiler","content":" Pour lancer votre projet, il vous suffit maintenant d'appuyer sur le petit insecte depuis VSCode. La première fois, il va vous demander quel compilateur vous voulez utiliser : il faudra probablement faire [Scan for kits], puis sélectionnez le compilateur qui mentionne amd64.   ","version":"Next","tagName":"h2"},{"title":"Partie 2 - Bases du rendu","type":0,"sectionRef":"#","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu","content":"","keywords":"","version":"Next"},{"title":"La structure de l'application​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#la-structure-de-lapplication","content":" Pour l'instant dans src/main.cpp vous avez ceci :  #include &quot;opengl-framework/opengl-framework.hpp&quot; // Inclue la librairie qui va nous servir à faire du rendu int main() { // Initialisation gl::init(&quot;TPs de Rendering&quot;); // On crée une fenêtre et on choisit son nom gl::maximize_window(); // On peut la maximiser si on veut while (gl::window_is_open()) { // Rendu à chaque frame } }   La boucle while est ce qu'on appelle la boucle de rendu ; chaque itération correspond à une frame, et il faudra y mettre le code dessinant ce qu'on veut pour cette frame.  En exécutant ce code, vous devriez avoir une fenêtre noire qui s'ouvre :  ","version":"Next","tagName":"h2"},{"title":"Couleur de fond​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#couleur-de-fond","content":" Pour commencer très simplement on peut choisir la couleur de fond, au début de la boucle de rendu :  glClearColor(0.f, 0.f, 1.f, 1.f); // Choisis la couleur à utiliser. Les paramètres sont R, G, B, A avec des valeurs qui vont de 0 à 1 glClear(GL_COLOR_BUFFER_BIT); // Exécute concrètement l'action d'appliquer sur tout l'écran la couleur choisie au-dessus     Note En plus de choisir la couleur, l'opération glClear(GL_COLOR_BUFFER_BIT) est très importante car elle reset l'image entre deux frames. Sans elle, les objets dessinés ne disparaissent pas d'une frame à l'autre (ce qui peut permettre des effets artistiques intéressants, mais est embêtant pour un rendu &quot;classique&quot;). Vous pourrez essayer ça un peu plus tard quand nous saurons dessiner des objets qui bougent.  ","version":"Next","tagName":"h2"},{"title":"OpenGL​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#opengl","content":" Nous utilisons l'API OpenGL pour communiquer avec la carte graphique. Il en existe d'autres, mais elles sont soit plus difficiles à apprendre (Vulkan, WebGPU), soit spécifiques à un OS (DirectX pour Windows, Metal pour Mac).  Si jamais vous cherchez de l'aide sur Internet ou ChatGPT, pensez à bien préciser OpenGL dans votre recherche. Et sinon, vous trouverez la documentation de toutes les fonctions OpenGL sur docs.gl.  Remarque Tout ce qui commence par gl:: (comme gl::init()) ne fait pas partie de l'API OpenGL de base, mais d'un wrapper que je vous fournis pour vous simplifier la vie. Par contre ce qui commence par gl (comme glClearColor) fait partie de l'API OpenGL officielle.  ","version":"Next","tagName":"h2"},{"title":"Mesh​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#mesh","content":" ","version":"Next","tagName":"h2"},{"title":"Vertex Buffer et Premier Triangle​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#vertex-buffer-et-premier-triangle","content":" Nous allons maintenant dessiner notre premier objet ! Pour décrire notre objet à la carte graphique, nous utilisons un mesh, c'est-à-dire une longue liste de triangles qui, mis bout-à-bout, dessinent notre forme en 3D :    Pendant l'initialisation nous pouvons créer un objet de type gl::Mesh :  auto const triangle_mesh = gl::Mesh{{ .vertex_buffers = {{ .layout = {gl::VertexAttribute::Position2D{0 /*Index de l'attribut dans le shader, on en reparle juste après*/}}, .data = { -1.f, -1.f, // Position2D du 1er sommet +1.f, -1.f, // Position2D du 2ème sommet 0.f, +1.f // Position2D du 3ème sommet }, }}, }};   que nous allons ensuite dessiner à chaque frame dans la boucle de rendu :  gl::bind_default_shader(); // On a besoin qu'un shader soit bind (i.e. &quot;actif&quot;) avant de draw(). On en reparle dans la section d'après. triangle_mesh.draw(); // C'est ce qu'on appelle un &quot;draw call&quot; : on envoie l'instruction à la carte graphique de dessiner notre mesh.     Il y a déjà plein de chose à dire ! Quand on crée un mesh, on lui passe un vertex buffer :  .vertex_buffers = {{ .layout = {gl::VertexAttribute::Position2D{0 /*Index de l'attribut dans le shader, on en reparle juste après*/}}, .data = { -1.f, -1.f, // Position2D du 1er sommet +1.f, -1.f, // Position2D du 2ème sommet 0.f, +1.f // Position2D du 3ème sommet }, }},   Un vertex buffer c'est le tableau qui contient toutes les données décrivant notre mesh : position des sommets des triangles, mais également plein d'autres données optionnelles : couleur, normale, coordonnée de texture (UV), etc. En fait c'est nous qui décidons quoi mettre dans ce buffer, puis que faire de ces données quand on code le vertex shader (que nous verrons plus tard). Pour faire du rendu classique on utilise généralement position + normales + UV. Mais on peut aussi imaginer d'autres usages plus créatifs et rajouter toutes les données dont on pourrait avoir besoin pour un effet précis.  Remarque Un usage original : on peut stocker la distance au tronc sur chaque vertex des branches et feuilles des arbres. Cette distance est ensuite utilisée pour calculer à quel point la branche peut ployer sous l'effet du vent. (La partie attachée au tronc ne doit pas bouger, et plus on s'en éloigne plus on peut bouger librement). Stocker cette distance dans le vertex buffer évite de la recalculer à chaque frame : c'est beaucoup plus optimisé. C'est utilisé dans God of War par exemple :  Décrire ce vertex buffer se passe en deux étapes : son layout et ses data. Le layout indique comment data est structuré : dans notre exemple on a juste des positions 2D qui s'enchaînent, mais ça pourrait aussi être des positions 3D, et on pourrait aussi avoir d'autres attributs dans le même tableau data, par exemple des coordonnées de texture, comme on verra plus tard. Pour chaque attribut du layout, il faut préciser son index (0 dans notre cas), une information qui nous servira plus tard pour récupérer l'attribut du côté du shader.  Vous remarquerez aussi que vertex_buffers est un tableau de vertex buffers ! Il est en effet possible d'avoir plusieurs vertex buffers, par exemple un qui stocke les positions, et un autre qui stocke les normales. Ça revient au même que de mettre tous les attributs dans le même vertex buffer, mais ça peut avoir des performances soit meilleures soit pires, en fonction des situations. C'est une question un peu compliquée dont nous ne soucierons pas, et nous utiliserons simplement ce qui est le plus pratique pour nous.  Enfin, dans data nous mettons nos positions 2D :  .data = { -1.f, -1.f, // Position2D du 1er sommet +1.f, -1.f, // Position2D du 2ème sommet 0.f, +1.f // Position2D du 3ème sommet },   Le système de coordonnées marche ainsi : x et y vont toujours de -1 à 1. Ainsi, x = -1 représente toujours le côté gauche de la fenêtre, et y = 1 représente toujours le haut de la fenêtre. Vous remarquerez donc que quand vous redimensionnez la fenêtre, le triangle se &quot;déforme&quot; pour continuer à remplir toute la fenêtre. Ce n'est généralement pas ce qu'on veut, et nous verrons comment remédier à ça plus tard.  ","version":"Next","tagName":"h3"},{"title":"RenderDoc​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#renderdoc","content":" Avant d'aller plus loin, nous allons commencer à découvrir RenderDoc, un super outil qui nous permettra de débuguer si jamais notre rendu ne se fait pas comme on voudrait.  Remarque Si jamais vous avez besoin de RenderDoc dans Unreal ou Unity, c'est possible ! Vous pouvez ouvrir ces moteurs directement dans RenderDoc, mais même encore mieux il y a un plugin RenderDoc pour Unreal, et le Frame Debugger pour Unity qui est un équivalent de RenderDoc intégré directement dans Unity.  La première chose à faire quand vous ouvrez RenderDoc, c'est d'aller dans l'onglet Launch Application pour choisir l'exécutable à débuguer (qui va se trouver dans le dossier de votre projet, et le sous-dossier build. Il devrait s'appeler TPs-Rendering.exe):    Une fois que s'est fait, vous pouvez cliquer sur Launch :    qui va lancer votre application en &quot;mode RenderDoc&quot; :    Vous pouvez alors faire F12 pour capturer une frame, puis fermer l'application, et RenderDoc va vous permettre d'inspecter la frame que vous venez de capturer :    La première chose à regarder, c'est la timeline sur le côté, qui indique toutes les opérations OpenGL qui ont été exécutées pendant la frame. Vous pouvez cliquer sur chacune d'elle, et voir le rendu à ce moment là de la frame :    Dans notre cas c'est très simple, il y a la couleur de fond qui est faite avec glClear, puis le draw call de notre mesh avec glDrawArrays (le 3 indique qu'il y avait 3 sommets dans notre vertex buffer).  Ensuite on peut inspecter chaque étape du rendu en cliquant dessus. Ce qui va nous intéresser c'est le draw call de notre mesh, donc cliquez sur l'étape glDrawArrays.  La première chose à faire, si typiquement votre mesh ne s'affiche pas, c'est d'aller dans Overlay, et de sélectionner Highlight Drawcall. Ça va indiquer là où votre mesh a atterri à l'écran.    Si vous voyez bien votre mesh en magenta dans le draw call, mais qu'ensuite le triangle ne s'affiche pas, c'est déjà une très bonne information ! Dans ce cas vous pouvez ensuite passer le mode d'overlay en Depth Test, puis Stencil Test, puis Backface Cull. Si l'un d'eux affiche votre mesh en rouge, c'est que cette étape du rasterizer a décidé de skipper votre mesh. Nous reparlerons de ces étapes plus tard (Depth Test, Stencil Test, Backface Culling). Sinon, si tout est vert mais que votre mesh ne s'affiche quand même pas, c'est probablement au niveau du fragment shader qu'il y a un problème.  Si à l'inverse dès l'overlay Highlight Drawcall vous ne voyez pas votre mesh, alors c'est le mesh lui-même qui a un problème. Vous pouvez alors aller dans l'onglet Mesh Viewer :    Ici vous avez plein d'informations : d'abord la vue VS In vous montre votre mesh tel qu'il était avant le vertex shader :    Si votre mesh apparaît bien ici, tant mieux ! Et sinon, c'est probablement que votre vertex buffer n'est pas bon ! Vous pouvez inspecter votre vertex buffer dans la vue VS Input, et regarder si il y a des valeurs bizarres / pas assez de vertexs / un layout qui ne correspond pas à ce que vous pensiez avoir spécifié, etc. Dans cet example, on voit que tout va bien, et on retrouve les valeurs qu'on avait mises dans notre vertex buffer :    Ensuite, vous pouvez aller voir dans VS Out l'état de votre mesh après le vertex shader. Dans les sections suivantes nous appliquerons des transformations au mesh dans le vertex shader (déplacement, caméra, etc.), et vous pourrez voir le résultat ici :    Et une fois de plus, si vous avez besoin d'inspecter les valeurs précises, elles sont toutes dans la vue VS Output :    RenderDoc permet encore beaucoup d'autres choses, mais vous avez vu l'essentiel qui vous sauvera 99% du temps !  ","version":"Next","tagName":"h3"},{"title":"Dessiner un rectangle​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#dessiner-un-rectangle","content":" Maintenant, à vous de jouer ! Modifiez le code qui crée votre mesh afin d'avoir non plus un triangle, mais un rectangle qui prendra la moitié de l'écran. Il vous faudra dessiner deux triangles, et donc indiquer six sommets dans le vertex buffer.  Si vous avez un problème de rendu, pensez à aller voir dans RenderDoc ce qu'il se passe !    ","version":"Next","tagName":"h3"},{"title":"Index buffer​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#index-buffer","content":" Vous avez peut-être remarqué une chose en faisant le vertex buffer du rectangle, c'est que vous avez dû écrire certains sommets deux fois ! (Une fois pour dessiner le premier triangle, puis une deuxième fois pour le deuxième triangle). Et d'ailleurs, six sommets pour un rectangle ça fait beaucoup, 4 devraient suffire ! C'est un problème qui devient d'autant plus embêtant que sur un vrai mesh les sommets sont parfois partagés par bien plus que deux triangles, et donc doivent être dupliqués plein de fois, ce qui augmente considérablement la taille du mesh.  Heureusement, ce problème a une solution : l'index buffer !  Quand on crée notre gl::Mesh on peut, en plus du vertex buffer, spécifier un index buffer :  auto const rectangle_mesh = gl::Mesh{{ .vertex_buffers = {{ .layout = {gl::VertexAttribute::Position2D{0}}, .data = { -0.5f, -0.5f, // Position2D du 1er sommet +0.5f, -0.5f, // Position2D du 2ème sommet +0.5f, +0.5f, // Position2D du 3ème sommet -0.5f, +0.5f // Position2D du 4ème sommet }, }}, .index_buffer = { 0, 1, 2, // Indices du premier triangle : on utilise le 1er, 2ème et 3ème sommet 0, 2, 3 // Indices du deuxième triangle : on utilise le 1er, 3ème et 4ème sommet }, }};   Les indices dans l'index buffer vont par 3, et décrivent un triangle en indiquant quels sommets prendre dans le vertex buffer.    Le rendu est exactement le même, mais notre vertex buffer est plus simple à écrire, et plus léger pour l'ordinateur !  Vous allez pouvoir tester d'écrire vous-même un index buffer quand vous ferez un cube, mais avant cela il nous manque quelques étapes pour passer en 3D !  ","version":"Next","tagName":"h3"},{"title":"Shader​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#shader","content":" Un Shader est un programme exécuté par la carte graphique. Il existe deux principaux types de shaders :  Le Vertex Shader qui prend un sommet dans notre vertex buffer et le modifie (déplacement, application de la perspective 3D, etc.)Le Fragment Shader qui prend un pixel de notre triangle et le colorie (en fonction de son matériau, de la lumière, etc.)  Remarque Il existe aussi les Compute Shaders qui sont plus génériques et prennent n'importe quel type de buffer et le modifient. Ils sont très utilisés pour faire des simulations sur GPU (particules, fluides, vêtements, etc.).  Pour créer un shader, il vous suffit de faire, dans l'initialisation :  auto const shader = gl::Shader{{ .vertex = gl::ShaderSource::File{&quot;res/vertex.glsl&quot;}, .fragment = gl::ShaderSource::File{&quot;res/fragment.glsl&quot;}, }};   et de créer les deux fichiers correspondants, dans le dossier res :  res/vertex.glsl #version 410 layout(location = 0) in vec2 in_position; void main() { gl_Position = vec4(in_position, 0., 1.); }   res/fragment.glsl #version 410 out vec4 out_color; void main() { out_color = vec4(1.); }   IMPORTANT Tous les assets (shader, texture, modèle 3D, etc.) doivent être mis dans le dossier res, et pas un autre, car ce dossier est copié pour être mis à côté de l'exe dans le dossier build. (C'est fait dans le CMakeLists.txt, par la ligne gl_target_copy_folder(${PROJECT_NAME} res)). Si jamais vous vouliez renommer le dossier res ou en ajouter un autre, il faudrait bien penser à aller modifier le CMakeLists.txt !  Puis pour utiliser ce shader à la place du shader par défaut, remplacez la ligne gl::bind_default_shader(); par shader.bind(); :    Le rendu n'a toujours pas changé, car les shaders que je vous ai donnés sont équivalents aux shaders par défaut qu'on utilisait jusque là. Mais ça ne saurait tarder, nous allons maintenant pouvoir modifier nos shaders comme on veut ! Mais avant tout, quelques explications :  ","version":"Next","tagName":"h2"},{"title":"GLSL​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#glsl","content":" Déjà, le GLSL est le langage utilisé pour écrire des shaders. Il ressemble très fort à du C, avec en plus quelques fonctions et types très souvent utilisés en rendu 3D : vecteurs (vec2, vec3, vec4), matrices (mat2, mat3, mat4), et fonctions géométriques (produit scalaire dot(v1, v2), normalisation d'un vecteur normalize(v), etc.).  Chaque shader doit commencer par une indication de la version utilisée (#version 410). Nous utilisons la 410, qui est la dernière supportée par MacOS. (Et sinon elles vont jusqu'à 460, mais il n'y a aucune différence en ce qui nous concerne).  ","version":"Next","tagName":"h3"},{"title":"Vertex Shader​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#vertex-shader","content":" Le vertex shader commence par une déclaration des attributs :  layout(location = 0) in vec2 in_position;   Ces attributs doivent correspondre au layout de notre vertex buffer :  .vertex_buffers = {{ .layout = {gl::VertexAttribute::Position2D{0 /*Index de l'attribut dans le shader*/}}, .data = { // ... }, }},   Le layout(location = 0) correspond à l'index 0 spécifié pour gl::VertexAttribute::Position2D, et le type vec2 vient du fait que nos positions 2D sont des vecteurs à deux composantes (si on utilisait des positions 3D, il faudrait mettre vec3). Le nom in_position est libre et vous pouvez mettre ce que vous voulez.  Ensuite, dans la fonction main() on assigne la variable gl_Position, qui est une variable spéciale indiquant à OpenGL la position finale du vertex (ce qui correspond au VS Out qu'on avait vu dans RenderDoc).  En guise de premier exercice, vous pouvez déplacer le rectangle via le vertex shader, par exemple de 0.4 en x et en y :    ","version":"Next","tagName":"h3"},{"title":"Fragment Shader​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#fragment-shader","content":" Le fragment shader commence par  out vec4 out_color;   qui déclare la variable de sortie : ce qu'on assigne à cette variable correspondra à la couleur du pixel à l'écran.  Et dans le main() on fait quelque chose de très simple, qui est d'assigner la même couleur à tous les pixels, sans réfléchir :  out_color = vec4(1.);   Note La syntaxe vec4(1.) est un raccourci pour vec4(1., 1., 1., 1.). On peut même faire des choses comme vec4(vec3(0.5), 1.), qui revient à faire vec4(0.5, 0.5, 0.5, 1.).Les composantes R, G, B et A des couleurs vont de 0 à 1, donc vec3(1., 1., 1.) correspond à mettre le maximum de rouge, vert et bleu, donc du blanc pur.  En guise de premier exercice, vous pouvez changer la couleur du rectangle :    ","version":"Next","tagName":"h3"},{"title":"Envoyer des paramètres au shader : les uniforms​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#envoyer-des-paramètres-au-shader--les-uniforms","content":" Pour que nos shaders deviennent intéressants, il faut leur envoyer plus de données en entrée. On peut soit rajouter des attributs dans le vertex buffer (couleur, UV, normale, etc.), ce que nous verrons plus tard ; soit envoyer des paramètres appelés uniforms. Une variable uniforme se déclare ainsi dans le shader, au-dessus du main() :  uniform vec2 nom_de_votre_variable_uniforme; // Vous pouvez mettre le type que vous voulez, et le nom que vous voulez   puis peut s'utiliser dans votre shader comme vous le voulez, comme n'importe quelle variable normale.  Pour assigner la valeur d'une variable uniforme, cela se fait dans votre code C++, après avoir bind le shader :  shader.set_uniform(&quot;nom_de_votre_variable_uniforme&quot;, glm::vec2{1.f, 3.f});   Remarque On utilise la librairie glm pour avoir des types vecteur et matrice comme en glsl : glm::vec2, glm::vec3, glm::vec4, glm::mat2, glm::mat3, glm::mat4, etc.  Note Une variable uniform s'appelle ainsi car elle est uniforme pour un draw call : ça sera la même pour tous les vertexs et pour tous les pixels lors d'un appel donné à mesh.draw(). Si on voulait une valeur qui est différente pour chaque vertex, il faudrait passer par un attribut de vertex.  On peut par exemple utiliser les uniforms pour régler notre problème de taille de rectangle qui suit la fenêtre. Pour cela, nous allons passer au shader l'aspect ratio de la fenêtre (i.e. largeur / hauteur), et corriger la position en x de nos vertexs en fonction du ratio.  Déclarez une uniform aspect_ratio de type float dans le vertex shaderDivisez le x de la position de votre vertex par aspect_ratioCôté C++, passez la uniform au shader (Vous pouvez obtenir l'aspect ratio de la fenêtre avec gl::framebuffer_aspect_ratio())  Enfin un carré qui reste carré peu importe la taille de la fenêtre !  Remarque On pourrait se dire qu'il suffisait de créer un nouveau vertex buffer avec des positions qui prennent en compte l'aspect ratio, et de recréer le buffer à chaque fois que l'aspect ratio change. Mais ça impliquerait de modifier potentiellement les millions de vertexs de notre mesh, ce qui prendrait beaucoup de temps. Alors que le vertex shader lui va faire ça en un rien de temps : c'est la puissance de la carte graphique, qui peut traiter tous les sommets en parallèle extrêmement vite !  ","version":"Next","tagName":"h3"},{"title":"Exercice : Faire bouger le carré​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#exercice--faire-bouger-le-carré","content":" Vous pouvez utiliser gl::time_in_seconds() pour récupérer le temps, l'envoyer au shader, et vous en servir pour faire bouger le carré. Le plus simple est de le faire aller en ligne droite, mais vous pouvez aussi (bonus) le faire aller et revenir, ou tourner en rond :     Remarque Maintenant qu'on a un objet qui bouge, on peut enfin tester ce qu'il se passe quand on enlève la ligne glClear(GL_COLOR_BUFFER_BIT);. Je vous laisse essayer !  ","version":"Next","tagName":"h3"},{"title":"Bonus : effet de fade​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#bonus--effet-de-fade","content":" Vous avez toutes les cartes en main pour faire cet effet de fade, alors je vous laisse chercher comment faire 😉  Info Vous aurez probablement besoin d'utiliser de la transparence à un moment, qui nécessite d'être activée, au début de l'initialisation, avec : glEnable(GL_BLEND); glBlendFuncSeparate(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA, GL_ONE_MINUS_DST_ALPHA, GL_ONE); // On peut configurer l'équation qui mélange deux couleurs, comme pour faire différents blend mode dans Photoshop. Cette équation-ci donne le blending &quot;normal&quot; entre pixels transparents.     Remarque Si vous voyez un effet de clignotement, c'est normal, c'est dû à la swapchain : en fait il y a deux images qui s'alternent : l'une qui est affichée à l'écran, et l'autre sur laquelle on est en train de dessiner. (Si on dessinait sur l'image qui est actuellement affichée à l'écran, on verrait les pixels se dessiner petit à petit et ça ferait très moche). Pour résoudre ce clignotement, il faudrait faire le rendu de toute notre scène dans une render target à part, qu'on copierait à l'écran à la fin de chaque frame. Nous verrons cette notion plus tard.  Remarque Il reste une trace qui ne s'efface pas, c'est dû à des problèmes d'arrondi au moment du calcul de la transparence, car chaque canal de couleur est stocké sur un entier à 8 bits seulement (par défaut). En faisant notre rendu sur une render target utilisant 16 bits par canal, ça résoudrait le problème.  Remarque Cet effet dépend du framerate ! Si vous dessinez deux fois plus d'images par seconde, la trace va s'effacer deux fois plus vite. Pour éviter cela, il faudrait prendre en compte gl::delta_time_in_seconds(), qui donne le temps écoulé entre deux frames.  ","version":"Next","tagName":"h3"},{"title":"Caméra et Matrices​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#caméra-et-matrices","content":" Il est temps de passer en 3D !  Pour cela nous avons besoin de deux informations :  Le point de vue, i.e. savoir où on est dans l'espace, et dans quelle direction on regardeLa projection, pour donner l'effet de perspective inhérent à la 3D  Pour représenter ces deux informations, nous allons utiliser des matrices. Une matrice est un objet mathématique qui permet de représenter une transformation géométrique. On applique une matrice à un vecteur (point ou direction, en 2D ou en 3D) pour lui appliquer la transformation géométrique représentée par la matrice. Par exemple on peut créer une matrice de rotation qui, quand elle est appliquée à un point, fait tourner ce point.  Remarque Une matrice est un grille de nombre. Par exemple une matrice 3D (mat3) ressemblerait à : (104012001)\\begin{pmatrix} 1 &amp; 0 &amp; 4 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix}​100​010​421​​ Je ne rentrerai pas dans les détails de quels nombres mettre dans la matrice pour représenter quelle transformation, car nous allons utiliser la librairie glm pour créer toutes ces matrices.  Le gros intérêt des matrices est qu'on peut les combiner entre elles en les multipliant ! Par exemple si j'ai une matrice 3D de rotation R et une matrice 3D de translation T, alors R * T est une nouvelle matrice 3D, dont la transformation géométrique est une translation suivie d'une rotation (NB : la transformation de droite est appliquée en première).  On peut ainsi construire une seule matrice finale, représentant la combinaison du point de vue (view matrix) et de la projection (projection matrix). On peut aussi y rajouter une modification de notre mesh (pour faire tourner le mesh, le translater pour le positionner dans le monde où on veut, etc.) (model matrix). Ensuite on envoie cette seule matrice au shader, il l'applique à la position de nos vertexs, et le tour est joué !  Attention L'ordre des matrices a son importance ! R * T est différent de T * R. T * R est une rotation suivie d'une translation, ce qui est différent de d'abord faire la translation puis la rotation, comme vous pourrez le constater dans l'exercice qui suit.  Remarque On ne peut pas représenter n'importe quelle transformation géométrique avec des matrices, seulement celles qui sont affines. Mais c'est déjà bien assez, car les translations, les rotations et les aggrandisements sont toutes des transformations affines. Vous pouvez tester cette démo interactive pour voir quel genre de transformation géométrique une matrice peut produire, et aussi regarder cette excellentissime vidéo.  ","version":"Next","tagName":"h2"},{"title":"View Matrix​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#view-matrix","content":" Pour obtenir la View Matrix nous allons utiliser une caméra, que nous pourrons contrôler pour se déplacer dans le monde :  // Dans l'initialisation auto camera = gl::Camera{};   puis, pour que la caméra puisse réagir aux évènements (clic, déplacement de la souris, etc.), il faut la connecter aux évènements fournis par la librairie gl :  // Dans l'initialisation gl::set_events_callbacks({camera.events_callbacks()});   Une fois que c'est fait, on peut récupérer la matrice de vue avec :  // À chaque frame glm::mat4 const view_matrix = camera.view_matrix();   Remarque gl::set_events_callbacks() prend un tableau de callbacks, donc on pourrait rajouter nos propres callbacks en plus de ceux de la caméra : gl::set_events_callbacks({ camera.events_callbacks(), { .on_mouse_pressed = [&amp;](gl::MousePressedEvent const&amp; e) { std::cout &lt;&lt; &quot;Mouse pressed at &quot; &lt;&lt; e.position.x &lt;&lt; &quot; &quot; &lt;&lt; e.position.y &lt;&lt; '\\n'; }, }, });   ","version":"Next","tagName":"h3"},{"title":"Projection Matrix​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#projection-matrix","content":" Il nous faut encore la matrice de projection. Celle-ci est plus simple et s'obtient directement grâce à glm :  glm::mat4 const projection_matrix = glm::infinitePerspective(1.f /*field of view in radians*/, gl::framebuffer_aspect_ratio() /*aspect ratio*/, 0.001f /*near plane*/);   (Attention, il faudra inclure le bon fichier de glm au début de main.cpp : #include &quot;glm/ext/matrix_clip_space.hpp&quot;)  Ses différents paramètres sont :  Le field of view (angle de vue). Vous avez peut-être déjà vu ce paramètre dans des jeux vidéos. Plus il est large, plus on voit une grande partie de la scène à la fois (attention, avec des valeurs trop grande les objets commencent à apparaître déformés), plus il est petit moins on voit une grande portion de la scène, ça zoom. Attention, il est exprimé en radians, donc pour un fov de 45° il faudra écrire glm::radians(45.f).L'aspect ratio de la fenêtre. La petite division par aspect_ratio qu'on avait fait précédemment pour corriger notre problème de stretch est gérée automatiquement par la matrice de projection, vous pouvez donc enlever cette ligne du vertex shader.Le near plane : à cause de limitations techniques, les objets trop proches de la caméra ne peuvent pas être visibles. Le near plane définit à partir de quelle distance on commence à voir les objets. Plus on le met proche de 0, plus on évitera d'avoir des objets coupés, mais si on le met trop petit on peut commencer à avoir des erreurs d'arrondis dans nos calculs entre float, ce qui causerait d'autres problèmes dans notre rendu.Le far plane : on n'en a pas ici car on utilise glm::infinitePerspective(), mais si on utilisait glm::perspective() on en aurait un. Similaire au near plane, il définit la distance à partir de laquelle on ne voit plus les objets.  Remarque Il y a aussi un autre type de projection : la projection orthographique. Elle ne fait pas intervenir de perspective, donc les objets lointains apparaissent à la même taille que les objets proches. Ce n'est pas réaliste, mais peut être intéressant pour donner un style au rendu.  ","version":"Next","tagName":"h3"},{"title":"Envoyer au shader​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#envoyer-au-shader","content":" Maintenant qu'on a ces deux matrices, on peut les multiplier entre elles pour former la view_projection_matrix (⚠ Attention, la view doit s'appliquer en premier, et la projection en deuxième ! Réfléchissez donc bien à l'ordre dans lequel vous multipliez vos matrices), et envoyer cette view_projection matrix au shader (déclarez une uniform de type mat4). Enfin, il ne reste plus qu'à multiplier dans le shader la matrice à la position de nos vertexs :  gl_Position = view_projection_matrix * vec4(in_position, 0., 1.);   Remarque Nos matrices sont des mat4 alors qu'on est en 3D. C'est parce qu'on utilise une &quot;astuce&quot; qui sont les coordonnées homogènes, et sans lesquelles on ne pourrait pas faire de translation ni de perspective. C'est pour ça qu'on a besoin de rajouter une coordonnée de plus que la dimension de l'espace. C'est aussi pour ça qu'on rajoute un 1 en quatrième coordonnée de nos positions (vec4(in_position, 0., 1.)).    ","version":"Next","tagName":"h3"},{"title":"Exercice : paramètres de la projection​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#exercice--paramètres-de-la-projection","content":" Essayez de changer les paramètres de la matrice de projection (field of view, near plane) et essayez d'observer la différence de rendu. Essayez aussi d'utiliser une projection orthographique. (Je vous laisse chercher en ligne comment on fait ça avec glm).  ","version":"Next","tagName":"h3"},{"title":"Exercice : model matrix​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#exercice--model-matrix","content":" On peut rajouter un troisième matrice à la view_projection_matrix, pour former la model_view_projection_matrix ! (Attention, la model matrix doit s'appliquer en premier).  Avec glm vous pouvez créer une matrice de rotation avec  glm::mat4 const rotation = glm::rotate(glm::mat4{1.f}, gl::time_in_seconds() /*angle de la rotation*/, glm::vec3{0.f, 0.f, 1.f} /* axe autour duquel on tourne */);   et une matrice de translation avec  glm::mat4 const translation = glm::translate(glm::mat4{1.f}, glm::vec3{0.f, 1.f, 0.f} /* déplacement */);   (Il faudra include #include &quot;glm/ext/matrix_transform.hpp&quot;.)  Créez une matrice modèle qui combine une translation et une rotation, et observez le résultat. Essayez les deux ordres (rotation suivie de translation, et vice-versa) et vous verrez que ce n'est pas pareil ! L'ordre a son importance !  ","version":"Next","tagName":"h3"},{"title":"Cube​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#cube","content":" Maintenant qu'on peut voir en 3D, il est temps de faire notre premier mesh 3D ! Faites le vertex buffer et l'index buffer pour un cube. Je vous laisse revoir le chapitre dédié au besoin. Je vous conseille de faire des petits schémas pour ne pas vous y perdre dans les indices, et y aller face par face.  Attention Pensez à modifier aussi votre shader, pour qu'il reçoive une position 3D et plus 2D.    ","version":"Next","tagName":"h2"},{"title":"Premier shader pour mieux voir la 3D​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#premier-shader-pour-mieux-voir-la-3d","content":" On a du mal à discerner la 3D sur notre cube monochrome. Nous allons donc changer notre fragment shader pour commencer à un peu mieux voir tout ça.  Une manière très simple va être de passer la position des vertexs du vertex shader vers le fragment shader, puis d'utiliser ces positions comme des couleurs, afin que chaque vertex ait une couleur différente.  Pour cela dans le vertex shader nous allons déclarer une variable out, qui sera transmise au fragment shader automatiquement :  res/vertex.glsl // À mettre avant le main out vec3 vertex_position;   puis on l'assigne dans le main :  res/vertex.glsl vertex_position = in_position;   et ensuite dans le fragment shader on déclare un variable in avec le même nom et le même type que la variable out de notre vertex shader :  res/fragment.glsl // À mettre avant le main in vec3 vertex_position;   et on peut l'utiliser dans notre main :  res/fragment.glsl out_color = vec4(vertex_position, 1.);     Si votre cube vous paraît un peu bizarre, c'est normal, il nous manque encore un Depth Buffer pour faire de la 3D correctement !  ","version":"Next","tagName":"h2"},{"title":"Depth Buffer​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#depth-buffer","content":" Le problème avec notre rendu pour l'instant, c'est que les triangles se dessinent les uns après les autres et se recouvrent. Et si par malchance c'est une face arrière du cube qui est dessinée en dernière, alors elle va venir cacher les faces avant qui ont été dessinées avant.  Pour remédier à ça, il faut activer le Depth Test :  // À mettre dans l'initialisation glEnable(GL_DEPTH_TEST);   et clear le depth buffer à chaque frame, tout comme on clear la couleur de l'écran :  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // Vient remplacer glClear(GL_COLOR_BUFFER_BIT);     Et voilà ! Notre premier rendu 3D qui ressemble à peu près à quelque chose ! 🎉  Et qu'est-ce donc qu'un Depth Buffer au fait ? C'est une deuxième image, qui se crée en parallèle de la couleur qu'on met à l'écran, et qui stocke la profondeur correspondant à chaque pixel. Ainsi chaque triangle dessine à la fois une couleur à l'écran (contrôlée par le fragment shader), et aussi une &quot;couleur&quot; dans le depth buffer. Et avant même de dessiner, on vérifie pour chaque pixel si il n'y avait pas déjà eu quelque chose de dessiné sur ce pixel, et si oui on compare leur profondeur, et on recolorie le pixel avec la nouvelle couleur seulement si il est plus proche de la caméra que l'objet précédemment dessiné (on obtient cette distance à la caméra justement en allant lire le depth buffer).  On peut aller visualiser notre Depth Buffer dans RenderDoc :    Dans l'onglet Outputs il y a maintenant deux images : l'écran normal (Backbuffer Color), et le Depth Buffer (Backbuffer Depth-stencil). (NB : pour y voir quelque chose dans le depth buffer, il faut changer la Range, car comme le cube est très proche il apparaît très blanc dans le depth buffer).  Remarque On verra un usage créatif du depth buffer pour faire un effet de rendu See-Through.  ","version":"Next","tagName":"h2"},{"title":"Texture​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#texture","content":" ","version":"Next","tagName":"h2"},{"title":"Bonus : textures procédurales en fonction des uvs, cf. Shadertoy​","type":1,"pageTitle":"Partie 2 - Bases du rendu","url":"/Rendering/M1 GP/Partie 2 - Bases du rendu#bonus--textures-procédurales-en-fonction-des-uvs-cf-shadertoy","content":"","version":"Next","tagName":"h3"}],"options":{"id":"default"}}